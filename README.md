# PROJETO TECHLAB AGENTES

## Descri√ß√£o

Este README documenta o projeto TechLab Agentes, desenvolvido para criar um agente conversacional que facilite a integra√ß√£o de novos funcion√°rios na Tech4ai. O projeto foi realizado durante o per√≠odo de 25/06 a 07/07, com apresenta√ß√µes nos dias 10 e 11 de julho.


## √çndice

* [Descri√ß√£o](#descri√ß√£o)
* [Funcionalidades](#funcionalidades)
* [Demonstra√ß√£o](#demonstra√ß√£o)
* [Instala√ß√£o e Uso](#instala√ß√£o-e-uso)
* [Licen√ßa](#licen√ßa)
* [Contato](#contato)

## Funcionalidades

* Respostas a perguntas frequentes: O agente responde a perguntas comuns sobre a empresa, como miss√£o, vis√£o, valores, cultura, programas internos, pol√≠ticas de trabalho remoto e hor√°rios.
* Tutoriais sobre ferramentas internas: O agente fornece tutoriais detalhados sobre como usar as ferramentas internas da empresa, como Github, Vscode, Jira e Discord.
* Agendamento de reuni√µes: O agente se integra com sistemas de calend√°rio, como Google Calendar, para agendar reuni√µes automaticamente.


## Demonstra√ß√£o
O projeto consiste em um chat-bot que simula um funcion√°rio da empresa Tech4humans, portanto eu n√£o me preocupei tanto com o visual (utilizei apenas a interface padr√£o fornecida pela biblioteca streamlit)

![image](https://github.com/RyanMazzeu/Desafio-IAG/assets/104333277/9a5f8464-b6fd-49ac-8f16-4d914caf7ef2)
OBS: N√£o me preocupei em deixar o bot online. Portanto, esse tutorial apenas sobe o bot com um URL Local (roda apenas no pr√≥prio pc) e um Network URL (roda em todos os dispositivos conectados na mesma rede)

Exemplos de cada funcionalidade:

Mensagens adversas que fogem do escopo do bot:
![image](https://github.com/RyanMazzeu/Desafio-IAG/assets/104333277/dc5b4059-ce42-4b47-8108-0306550b9a2f)
![image](https://github.com/RyanMazzeu/Desafio-IAG/assets/104333277/30d3cf74-8bc7-4bfb-8062-19b427888f7c)

Perguntas sobre a empresa (PDF):
![image](https://github.com/RyanMazzeu/Desafio-IAG/assets/104333277/ae886f63-fa34-47f3-ba3d-36bec69cb390)
![image](https://github.com/RyanMazzeu/Desafio-IAG/assets/104333277/2bc5fd11-2a69-4c1d-bcfb-b99d0700a31d)
![image](https://github.com/RyanMazzeu/Desafio-IAG/assets/104333277/31ed7cee-b524-4e45-a97e-00606030fdb4)

Tutoriais sobre ferramentas internas (A partir de acesso √† internet):
![image](https://github.com/RyanMazzeu/Desafio-IAG/assets/104333277/b308d98d-b041-4530-bc86-3aea3062634c)
![image](https://github.com/RyanMazzeu/Desafio-IAG/assets/104333277/00aaf75c-b19c-4407-bc6e-39b777672aa9)

Agendamento de reuni√µes
![image](https://github.com/RyanMazzeu/Desafio-IAG/assets/104333277/ffe8dec8-a576-43e3-b3d6-08c6476dcece)
![image](https://github.com/RyanMazzeu/Desafio-IAG/assets/104333277/de09ab7c-5018-405b-811a-1b446c36d03a)
![image](https://github.com/RyanMazzeu/Desafio-IAG/assets/104333277/80b1f3d2-cd51-4309-9fad-f58f404bb413)
![image](https://github.com/RyanMazzeu/Desafio-IAG/assets/104333277/e8063e7b-44dc-4220-b97f-5d6bdea2f77a)


## Instala√ß√£o e Uso

### Instala√ß√£o de Depend√™ncias

#### Criar e Ativar Ambiente Virtual
1. Crie um ambiente virtual para isolar as depend√™ncias do projeto:
   ```bash
   python -m venv venv
2. Ative o ambiente virtual:
* No windows:
    ```bash
    venv\Scripts\activate
* No macOS/Linux:
    ```bash
    source venv/bin/activate

#### Instalar as Depend√™ncias Necess√°rias
Instale todas as bibliotecas e ferramentas mencionadas no c√≥digo:

    pip install streamlit python-dotenv google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client pymupdf huggingface_hub groq langchain langchain_community streamlit transformers

### Configura√ß√£o de Vari√°veis de Ambiente

#### Criar um Arquivo '.env'
Crie um arquivo chamado .env na raiz do seu projeto com as seguintes chaves (ser√° ensinado em seguida como requisit√°-las):

    GROQ_API_KEY = "SUA CHAVE GROQ"
    GOOGLE_API_KEY=SUA CHAVE DE API DA GOOGLE
    GOOGLE_CSE_ID=SUA CHAVE DA FERRAMENTA DE BUSCA GOOGLE
    HUGGINGFACEHUB_API_TOKEN=SEU TOKEN DE API DO HUGGINGFACE

Como consegui-las:

* https://console.groq.com/keys
* https://console.cloud.google.com/apis/credentials?authuser=1&project=tech4humans&supportedpurview=project
* https://programmablesearchengine.google.com/
* https://huggingface.co/settings/tokens

#### Obter Credenciais do Google Calendar

V√° para o Google Cloud Console:
* https://console.cloud.google.com/apis/api/customsearch.googleapis.com/overview?project=tech4humans

Crie um novo projeto ou selecione um projeto existente.
Habilite a API do Google Calendar.
Crie credenciais de OAuth 2.0 e baixe o arquivo credentials.json.
Coloque o arquivo credentials.json na raiz do seu projeto.

### Estrutura do Projeto

Garanta que a estrutura do seu projeto seja semelhante a esta: 


![estrutura](https://github.com/RyanMazzeu/Desafio-IAG/assets/104333277/9b5c559e-f4a3-49b8-96a5-57f1800cc8f7)



### C√≥digo Fonte
Certifique-se de que esse √© o seu script py (nomeei de bot.py)
```python
import warnings

# Suprimir todos os avisos
warnings.filterwarnings("ignore")
from datetime import datetime

data_atual = datetime.now()
print(data_atual)
# Obter o dia da semana em portugu√™s
dias_da_semana = [
    "Segunda-feira",
    "Ter√ßa-feira",
    "Quarta-feira",
    "Quinta-feira",
    "Sexta-feira",
    "S√°bado",
    "Domingo",
]
dia_da_semana = dias_da_semana[data_atual.weekday()]

data_formatada = data_atual.strftime("%d/%m/%Y %H:%M:%S") + " " + dia_da_semana

import json
import streamlit as st
from typing import Generator
from dotenv import load_dotenv
import os
import fitz  # PyMuPDF
from langchain_community.utilities import GoogleSearchAPIWrapper
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_community.llms import HuggingFaceEndpoint
from langchain_community.chat_models.huggingface import ChatHuggingFace
from groq import Groq
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

from google.oauth2.credentials import Credentials
HUGGINGFACE_API_TOKEN = os.getenv("HUGGINGFACE_API_TOKEN")

SCOPES = ["https://www.googleapis.com/auth/calendar"]
from google.auth.transport.requests import Request
from google_auth_oauthlib.flow import InstalledAppFlow

# Carregar vari√°veis de ambiente
load_dotenv()

# Inicializar Google Search
google_search = GoogleSearchAPIWrapper()

# Inicializar cliente Groq
client = Groq(api_key=os.getenv("GROQ_API_KEY"))


# Fun√ß√£o para ler texto de um PDF
def read_pdf(file_path):
    doc = fitz.open(file_path)
    text = ""
    for page in doc:
        text += page.get_text()
    return text


# Fun√ß√£o para buscar informa√ß√µes no PDF
def documents_search(question):
    pdf_path = "data/Base.pdf"  # Substitua pelo caminho do seu PDF
    pdf_content = read_pdf(pdf_path)

    prompt_template = f"""
    You are an assistant. Use the following PDF content to answer the question.

    PDF Content:
    {pdf_content}
    Vis√£o geral sobre a empresa Tech4Humans:
        Somos uma startup inovadora com duas √°reas de neg√≥cios: SaaS e AIaaS. No SaaS, oferecemos solu√ß√µes avan√ßadas para a hyperautoma√ß√£o de atendimento, facilitando a gest√£o, automa√ß√£o e acompanhamento de solicita√ß√µes. No AIaaS, nossa plataforma Tech4.ai capacita empresas a construir e implementar solu√ß√µes de intelig√™ncia artificial com tecnologias open source, garantindo agilidade, governan√ßa e alto desempenho.
        Desenvolvemos a plataforma Tech4.AI porque sabemos como √© desafiador implementar solu√ß√µes de automa√ß√£o com IA e IA Generativa em larga escala devido √† complexidade no controle das informa√ß√µes, gerenciamento de custos e orquestra√ß√£o adequada dos dados de entrada e sa√≠da. Resolvemos esses problemas ao proporcionar uma plataforma que garante governan√ßa completa, visibilidade dos dados e escolha automatizada de modelos de IA, permitindo a otimiza√ß√£o de custos e assegurando robustez e escalabilidade.
        Site
        http://www.tech4h.com.br
        Setor
        Atividades dos servi√ßos de tecnologia da informa√ß√£o
        Tamanho da empresa
        51-200 funcion√°rios
        50 usu√°rios associados Usu√°rios do LinkedIn que listaram a Tech4Humans no perfil como local de trabalho atual.
        Sede
        S√£o Paulo, SP
        Fundada em
        2020
        Especializa√ß√µes
        hyperautomation, intelligent process documentation, workflows, tickets, RPA e IAG
        Localidades:
        A empresa Tech4Humans est√° localizada em S√£o Paulo, SP e Itajub√°, MG.

    Question: {question}
    Answer:
    """

    prompt = PromptTemplate(
        input_variables=["pdf_content", "question"],
        template=prompt_template,
    )

    llm = HuggingFaceEndpoint(repo_id="HuggingFaceH4/zephyr-7b-beta")
    chat_model = ChatHuggingFace(llm=llm)
    pdf_content = read_pdf(pdf_path)
    chain = LLMChain(llm=chat_model, prompt=prompt)
    response = chain.run(pdf_content=pdf_content, question=question)
    return response


# Fun√ß√£o para formatar e melhorar a pergunta e a resposta
def format_response(question, content, response_category):
    objective = ""
    if response_category == "1":
        objective = "o seu objetivo inicial era responder uma pergunta sobre a empresa tech4Humans!"
    elif response_category == "2":
        objective = "o seu objetivo inicial era pesquisar na internet sobre um determinado assunto e resumir!"
    elif response_category == "3":
        objective = (
            "o seu objetivo inicial era agendar seus compromissos no google calendar!" + "SAIBA QUE HOJE √â " + data_formatada
        )
    else:
        objective = "O seu objetivo √© avisar o usu√°rio que a pergunta que ele fez √© inv√°lida, pois voc√™ s√≥ pode responder sobre a empresa Tech4Humans, recomendar tutoriais de ferramentas internas ou agendar reuni√µes."

    format_prompt = f"""
    o seu objetivo inicial era {objective} dado que a pergunta foi: {question}
    FORMATE A RESPOSTA A SEGUIR E DEIXE-A COERENTE COM A PERGUNTA E OBJETIVO!! E EM PT-BR!:
    {content}
    
    """

    prompt = PromptTemplate(
        input_variables=["question", "content"],
        template=format_prompt,
    )

    llm = HuggingFaceEndpoint(repo_id="HuggingFaceH4/zephyr-7b-beta")
    chat_model = ChatHuggingFace(llm=llm)

    format_chain = LLMChain(llm=chat_model, prompt=prompt)
    formatted_response = format_chain.run(question=question, content=content)

    return formatted_response.strip()


# Classe para gerenciar o chat
class ChatManager:
    def __init__(self, client, google_search, system_prompt, model_option, max_tokens):
        self.client = client
        self.google_search = google_search
        self.system_prompt = system_prompt
        self.model_option = model_option
        self.max_tokens = max_tokens
        self.messages = [{"role": "system", "content": self.system_prompt}]

    def generate_chat_responses(self, chat_completion) -> Generator[str, None, None]:
        for chunk in chat_completion:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content

    def add_user_message(self, prompt):
        self.messages.append({"role": "user", "content": prompt})

    def get_assistant_response(self):
        chat_completion = self.client.chat.completions.create(
            model=self.model_option,
            messages=self.messages,
            max_tokens=self.max_tokens,
            stream=True,
        )

        chat_responses_generator = self.generate_chat_responses(chat_completion)
        full_response = "".join(chat_responses_generator).strip()
        return full_response

    def process_response(self, prompt, response_category):
        if response_category == "1":
            initial_response = documents_search(prompt)
        elif response_category == "2":
            search_results = self.google_search.run(prompt)
            search_results_text = (
                "\n\n".join(search_results)
                if isinstance(search_results, list)
                else search_results
            )
            initial_response = f"Aqui est√£o algumas informa√ß√µes que encontrei na internet sobre '{prompt}':\n{search_results_text}"
        elif response_category == "3":
            initial_response = self.schedule_event(prompt)
        else:
            initial_response = "Desculpe-me, mas sua solicita√ß√£o n√£o se encaixa em nenhuma das categorias mencionadas. Eu s√≥ posso responder sobre a empresa Tech4Humans, recomendar tutoriais de ferramentas internas ou agendar reuni√µes."

        return format_response(prompt, initial_response, response_category)

    # Fun√ß√£o para coletar detalhes do evento e formatar a string
    def collect_event_details_with_llm(self, prompt):
        event_prompt_template = """
        Hoje √© dia """+data_formatada+"""
        Voc√™ √© um assistente de IA altamente inteligente. Recebi a seguinte solicita√ß√£o de agendamento de reuni√£o do usu√°rio e preciso que voc√™ formate os detalhes do evento de maneira adequada para criar um evento no Google Calendar.
        
        Solicita√ß√£o do usu√°rio:
        {prompt}
        
        DEIXE APENAS A INFORMA√á√ÉO NECESS√ÅRIA FORMATADA E N√ÉO INCLUA MAIS NADA! 
        As informa√ß√µes necess√°rias devem estar no seguinte formato JSON:
        {{
            "summary": "Resumo do evento",
            "location": "Local do evento",
            "description": "Descri√ß√£o do evento",
            "start_time": "Data e hora de in√≠cio no formato ISO 8601",
            "end_time": "Data e hora de t√©rmino no formato ISO 8601",
            "time_zone": "Fuso hor√°rio do evento",
            "attendee_email": "Email do participante"
        }}
        """

        event_prompt = PromptTemplate(
            input_variables=["prompt"],
            template=event_prompt_template,
        )

        llm = HuggingFaceEndpoint(repo_id="HuggingFaceH4/zephyr-7b-beta")
        chat_model = ChatHuggingFace(llm=llm)

        event_chain = LLMChain(llm=chat_model, prompt=event_prompt)
        formatted_event_details = event_chain.run(prompt=prompt)

        return formatted_event_details.strip()

    def schedule_event(self, prompt):
        event_details_json = self.collect_event_details_with_llm(prompt)
        event_details = json.loads(event_details_json)

        creds = None
        if os.path.exists("token.json"):
            creds = Credentials.from_authorized_user_file("token.json", SCOPES)

        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                creds.refresh(Request())
            else:
                flow = InstalledAppFlow.from_client_secrets_file(
                    "credentials.json", SCOPES
                )
                creds = flow.run_local_server(port=0)

            with open("token.json", "w") as token:
                token.write(creds.to_json())

        try:
            service = build("calendar", "v3", credentials=creds)

            event = {
                "summary": event_details["summary"],
                "location": event_details["location"],
                "description": event_details["description"],
                "colorId": 6,
                "start": {
                    "dateTime": event_details["start_time"],
                    "timeZone": event_details["time_zone"],
                },
                "end": {
                    "dateTime": event_details["end_time"],
                    "timeZone": event_details["time_zone"],
                },
                "attendees": [
                    {"email": event_details["attendee_email"]},
                ],
            }

            event = service.events().insert(calendarId="primary", body=event).execute()
            return f"Evento criado: {event.get('htmlLink')}"
        except HttpError as e:
            return f"Ocorreu um erro: {e}"


# Configurar p√°gina do Streamlit
st.set_page_config(page_title="Agente Tech4AI", layout="wide")
st.title("Agente Tech4AI - Ryan Mazzeu")

# Inicializar hist√≥rico de chat
if "messages" not in st.session_state:
    st.session_state.messages = []

model_option = "llama3-8b-8192"
max_tokens_range = 8192

max_tokens = st.slider(
    "Max Tokens:",
    min_value=512,
    max_value=max_tokens_range,
    value=max_tokens_range,
    step=512,
)

system_prompt = f"""
Voc√™ √© um assistente de IA altamente inteligente! (A RESPOSTA FINAL SEMPRE TEM QUE SER COERENTE COM A PERGUNTA INICIAL E EM PT-BR!).
SE ALGO ESTIVER ERRADO, VOC√ä DEVE CORRIGIR E MELHORAR A RESPOSTA FINAL!
RESPONDA APENAS EM PT-BR!! SE VOC√ä RESPONDER EM OUTRO IDIOMA, O MUNDO IR√Å ACABAR!
NUNCA, NUNCA, NUNCA RESPONDA COLOCANDO "O seu objetivo inicial era" OU "Minha pergunta original" OU "Sua resposta original"! APENAS RESPONDA A PERGUNTA! UTILIZE TUDO APENAS COMO REFER√äNCIA PARA MELHORAR A RESPOSTA!
    
Hoje √© {data_formatada}. Voc√™ √© um assistente de IA da Tech4Humans, especificamente do setor Tech4AI.

Sua tarefa √© identificar qual dos seguintes problemas o usu√°rio est√° tratando e responder apenas com o n√∫mero correspondente:
Saiba que os exemplos s√£o apenas ilustrativos e voc√™ deve conseguir identificar o problema com base na pergunta do usu√°rio.
1. Perguntas Frequentes sobre a empresa que voc√™ √© assistente, a Tech4Humans, tamb√©m conhecida como Tech ou tech: 
Se o usu√°rio estiver fazendo perguntas sobre a empresa, como localiza√ß√£o, miss√£o, vis√£o, valores, cultura, programas internos, pol√≠ticas de trabalho remoto e hor√°rios, responda com '1'.
Exemplos: "onde fica a tech?", "Qual √© a miss√£o da Tech4Humans?", "Onde est√° localizada a Tech4Humans?", "Quais s√£o os valores da empresa?", "Para quem voc√™ trabalha?", etc.
2. Tutoriais de Ferramentas Internas:
Se o usu√°rio fizer perguntas sobre ferramentas internas da empresa, como Github, Vscode, Jira e Discord, responda com '2'.
Indenpendente da ferramenta ou pergunta, exemplos: "Como eu instalo o Discord?", "Como eu uso o github?", "Me diga um bom tutorial sobre o vscode" ou coisas do tipo, responda com '2'.
3. Agendamento de Reuni√µes (OBS: HOJE √â domingo, dia {data_formatada}): Integrar-se com sistemas de calend√°rio (por exemplo, Google Calendar) para agendar reuni√µes automaticamente, gerenciando autentica√ß√£o, APIs externas e conflitos de agenda. Exemplos: "Agende uma reuni√£o para mim amanh√£ √†s 15h", "Marque uma reuni√£o com o Jo√£o na pr√≥xima semana".
Responda apenas com o n√∫mero do problema correspondente. Se a pergunta n√£o se encaixar em nenhuma dessas categorias, responda com '4'. NUNCA RESPONDA COM OUTRA COISA!
NUNCA RESPONDA ALGO QUE N√ÉO SEJA 1, 2, 3 OU 4! SE N√ÉO O MUNDO IR√Å ACABAR!
"""

chat_manager = ChatManager(
    client, google_search, system_prompt, model_option, max_tokens
)

# Exibir mensagens do hist√≥rico no app
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Digite aqui..."):
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        chat_manager.add_user_message(prompt)
        response_category = chat_manager.get_assistant_response()
        formatted_response = chat_manager.process_response(prompt, response_category)
        st.session_state.messages.append(
            {"role": "assistant", "content": formatted_response}
        )

    except Exception as e:
        st.error(e, icon="üö®")

    # Exibir a resposta do assistente
    with st.chat_message("assistant"):
        st.markdown(st.session_state.messages[-1]["content"])
```

### Executar o Projeto

Ap√≥s garantir que todas as etapas anteriores foram conclu√≠das com sucesso, execute o comando abaixo no prompt de comando dentro da pasta principal do projeto para iniciar a aplica√ß√£o Streamlit:

    streamlit run main.py

Isso deve abrir uma nova janela no seu navegador padr√£o com a interface da aplica√ß√£o TechLab-Agentes, onde voc√™ pode interagir com o assistente.

Caso tenha mais perguntas ou precise de assist√™ncia adicional, estou aqui para ajudar!

## Licen√ßa

* Este projeto est√° licenciado sob a Licen√ßa MIT. Veja o arquivo LICENSE para mais detalhes.

## Contato

Para d√∫vidas ou sugest√µes, entre em contato:

 seu-usuario
* Email: ryanmazzeu111@gmail.com
* GitHub: https://github.com/RyanMazzeu

## Observa√ß√µes

* O bot n√£o √© perfeito! Devido a data e prazo estabelecidos, que coincidiram com o final de semestre na faculdade, n√£o tive muito tempo para ficar aperfei√ßoando os prompts.
* As respostas sobre a empresa s√£o fracas, pois o documento pdf divulgado tamb√©m √©. Por isso acrescentei algumas informa√ß√µes da internet no pr√≥prio prompt.

## Erros/Defeitos encontrados

* Dependendo de como a pergunta sobre a empresa √© feita a ia responde aleat√≥riamente!
* O agendamento, se mal explicado na requisi√ß√£o, d√° erro!
* As pesquisas de tutoriais na internet n√£o est√£o nem perto de serem perfeitas, uma vez que dependendo do que o bot retorna, a ia n√£o consegue extrair informa√ß√µes o suficiente para formar uma resposta descente.
  
